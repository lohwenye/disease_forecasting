{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d5fbd620-b8b9-4d4f-a3a0-dd5c2c88ffdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 06 Combined Error Metrics\n",
    "## This code first combines all the predictions (from first order, forecast combination, and second order), then\n",
    "## calculates the error metrics in order to compare which forecast method is best"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "00b59e8e-a530-43c7-ba77-ddffe95c8c25",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_percentage_error, mean_absolute_error\n",
    "import itertools\n",
    "import statsmodels.api as sm\n",
    "import os\n",
    "from joblib import Parallel, delayed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a09f9f4d-d75c-4d10-8027-86238b8fd7b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from epiweeks import Week, Year\n",
    "from datetime import date\n",
    "def create_epiweek(date):\n",
    "    return Week.fromdate(date)\n",
    "def create_epiweekplot(epiweek):\n",
    "    epiweek = str(epiweek)\n",
    "    return F'Y{epiweek[:4]}W{epiweek[4:]}'\n",
    "def create_epiweek_fromstr(str):\n",
    "    return Week.fromstring(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "80be0930-470a-4ef2-bd9d-0653e0627a78",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Symmetrical Mean Absolute Percentage Error\n",
    "## Suitable for datasets where the actual values are small or close to 0\n",
    "\n",
    "def smape(A, F):\n",
    "    return 1/len(A) * np.sum(np.abs(F - A) / ((np.abs(A) + np.abs(F) + np.finfo(float).eps)/2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "486d08ba-3aa0-4c53-8c6e-19aa7c2d8fac",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_error_metrics(dataset, target_var):\n",
    "    pred = dataset.copy()\n",
    "    model_list = list(pred.columns.values)\n",
    "    y = pred[[target_var]]\n",
    "    model_list.remove(target_var)\n",
    "\n",
    "    error_df = pd.DataFrame()\n",
    "    #print(model_list)\n",
    "\n",
    "    for model in model_list:\n",
    "        model_val = pred[[model]].dropna()\n",
    "        window_start = model_val.index[0]\n",
    "        window_end = model_val.index[-1]\n",
    "        y_val = y.loc[window_start:window_end].copy()\n",
    "        error_df.at[model, 'MSE'] = mean_squared_error(y_val, model_val)\n",
    "        error_df.at[model, 'MAPE'] = mean_absolute_percentage_error(y_val, model_val)\n",
    "        error_df.at[model, 'MAE'] = mean_absolute_error(y_val, model_val)\n",
    "        error_df.at[model, 'SMAPE'] = smape(np.array(y_val), np.array(model_val))\n",
    "\n",
    "        '''\n",
    "        ## MASE: scale MAE to MAE of Naive Forecast (full naive forecast) -> wrong implementation!\n",
    "        error_df.at[model, 'MASE'] = error_df.at[model, 'MAE']/error_df.at['naive','MAE']\n",
    "        '''\n",
    "        \n",
    "        ## MASE: scale MAE to MAE of Naive Forecast (naive forecast window matched to model window)\n",
    "        naive_val = pred[['naive']].loc[window_start:window_end].copy()\n",
    "        error_df.at[model, 'MASE'] = mean_absolute_error(y_val, model_val)/mean_absolute_error(y_val, naive_val)\n",
    "\n",
    "        ## Diebold-Mariano against Naive\n",
    "        if model == 'naive':\n",
    "            dm_stat, pvalue = 0, 0\n",
    "        else:\n",
    "            dm_stat, pvalue = dm_test(y_val, naive_val, model_val)\n",
    "            if pvalue < 0.05:\n",
    "                pvalue = 'R'\n",
    "            else:\n",
    "                pvalue = 'A'\n",
    "\n",
    "        error_df.at[model, 'DM'], error_df.at[model, 'pval'] = dm_stat, pvalue\n",
    "\n",
    "    return error_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3b058c7a-b026-42f7-8c7b-5198d97332eb",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "from itertools import islice\n",
    "from typing import Sequence, Callable, List, Tuple\n",
    "from math import lgamma, fabs, isnan, nan, exp, log, log1p, sqrt\n",
    "\n",
    "\n",
    "class InvalidParameterException(Exception):\n",
    "    def __init__(self, message: str):\n",
    "        super().__init__(message)\n",
    "\n",
    "\n",
    "class ZeroVarianceException(ArithmeticError):\n",
    "    def __init__(self, message: str):\n",
    "        super().__init__(message)\n",
    "\n",
    "\n",
    "def autocovariance(X: Sequence[float], k: int, mean: float) -> float:\n",
    "    \"\"\"\n",
    "    Returns the k-lagged autocovariance for the input iterable.\n",
    "    \"\"\"\n",
    "    return sum((a - mean) * (b - mean) for a, b in zip(islice(X, k, None), X)) / len(X)\n",
    "\n",
    "\n",
    "def log_beta(a: float, b: float) -> float:\n",
    "    \"\"\"\n",
    "    Returns the natural logarithm of the beta function computed on\n",
    "    arguments `a` and `b`.\n",
    "    \"\"\"\n",
    "    return lgamma(a) + lgamma(b) - lgamma(a + b)\n",
    "\n",
    "\n",
    "def evaluate_continuous_fraction(\n",
    "    fa: Callable[[int, float], float],\n",
    "    fb: Callable[[int, float], float],\n",
    "    x: float,\n",
    "    *,\n",
    "    epsilon: float = 1e-10,\n",
    "    maxiter: int = 10000,\n",
    "    small: float = 1e-50\n",
    ") -> float:\n",
    "    \"\"\"\n",
    "    Evaluate a continuous fraction.\n",
    "    \"\"\"\n",
    "    h_prev = fa(0, x)\n",
    "    if fabs(h_prev < small):\n",
    "        h_prev = small\n",
    "\n",
    "    n: int = 1\n",
    "    d_prev: float = 0.0\n",
    "    c_prev: float = h_prev\n",
    "    hn: float = h_prev\n",
    "\n",
    "    while n < maxiter:\n",
    "        a = fa(n, x)\n",
    "        b = fb(n, x)\n",
    "\n",
    "        dn = a + b * d_prev\n",
    "        if fabs(dn) < small:\n",
    "            dn = small\n",
    "\n",
    "        cn = a + b / c_prev\n",
    "        if fabs(cn) < small:\n",
    "            cn = small\n",
    "\n",
    "        dn = 1 / dn\n",
    "        delta_n = cn * dn\n",
    "        hn = h_prev * delta_n\n",
    "\n",
    "        if fabs(delta_n - 1.0) < epsilon:\n",
    "            break\n",
    "\n",
    "        d_prev = dn\n",
    "        c_prev = cn\n",
    "        h_prev = hn\n",
    "\n",
    "        n += 1\n",
    "\n",
    "    return hn\n",
    "\n",
    "\n",
    "def regularized_incomplete_beta(\n",
    "    x: float, a: float, b: float, *, epsilon: float = 1e-10, maxiter: int = 10000\n",
    ") -> float:\n",
    "    if isnan(x) or isnan(a) or isnan(b) or x < 0 or x > 1 or a <= 0 or b <= 0:\n",
    "        return nan\n",
    "\n",
    "    if x > (a + 1) / (2 + b + a) and 1 - x <= (b + 1) / (2 + b + a):\n",
    "        return 1 - regularized_incomplete_beta(\n",
    "            1 - x, b, a, epsilon=epsilon, maxiter=maxiter\n",
    "        )\n",
    "\n",
    "    def fa(n: int, x: float) -> float:\n",
    "        return 1.0\n",
    "\n",
    "    def fb(n: int, x: float) -> float:\n",
    "        if n % 2 == 0:\n",
    "            m = n / 2.0\n",
    "            return (m * (b - m) * x) / ((a + (2 * m) - 1) * (a + (2 * m)))\n",
    "\n",
    "        m = (n - 1.0) / 2.0\n",
    "        return -((a + m) * (a + b + m) * x) / ((a + (2 * m)) * (a + (2 * m) + 1.0))\n",
    "\n",
    "    return exp(\n",
    "        a * log(x) + b * log1p(-x) - log(a) - log_beta(a, b)\n",
    "    ) / evaluate_continuous_fraction(fa, fb, x, epsilon=epsilon, maxiter=maxiter)\n",
    "\n",
    "\n",
    "def dm_test(\n",
    "    V: Sequence[float],\n",
    "    P1: Sequence[float],\n",
    "    P2: Sequence[float],\n",
    "    *,\n",
    "    loss: Callable[[float, float], float] = lambda u, v: (u - v) ** 2,\n",
    "    h: int = 1,\n",
    "    one_sided: bool = False,\n",
    "    harvey_correction: bool = True\n",
    ") -> Tuple[float, float]:\n",
    "    r\"\"\"\n",
    "    Performs the Diebold-Mariano test. The null hypothesis is that the two forecasts (`P1`, `P2`) have the same accuracy.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    V: Sequence[float]\n",
    "        The actual timeseries.\n",
    "\n",
    "    P1: Sequence[float]\n",
    "        First prediction series.\n",
    "\n",
    "    P2: Sequence[float]\n",
    "        Second prediction series.\n",
    "\n",
    "    loss: Callable[[float, float], float]\n",
    "        Loss function. At each time step of the series, each prediction is charged a loss, \n",
    "        computed as per this function. The Diebold-Mariano test is agnostic with respect to \n",
    "        the loss function, and this implementation supports arbitrarily specified (for example asymmetric) \n",
    "        functions. The two arguments are, *in this order*, the actual value and the predicted value. \n",
    "        Default is squared error (i.e. `lambda u, v: (u - v) ** 2`)\n",
    "\n",
    "    h: int\n",
    "        The forecast horizon. Default is 1.\n",
    "\n",
    "    one_sided: bool\n",
    "        If set to true, returns the p-value for a one-sided test instead of a two-sided test. Default is false.\n",
    "\n",
    "    harvey_correcetion: bool\n",
    "        If set to true, uses a modified test statistics as per Harvey, Leybourne and Newbold (1997).\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    A tuple of two values. The first is the test statistic, the second is the p-value.\n",
    "    \"\"\"\n",
    "    if not (len(V) == len(P1) == len(P2)):\n",
    "        raise InvalidParameterException(\n",
    "            \"Actual timeseries and prediction series must have the same length.\"\n",
    "        )\n",
    "\n",
    "    if h <= 0:\n",
    "        raise InvalidParameterException(\n",
    "            \"Invalid parameter for horizon length. Must be a positive integer.\"\n",
    "        )\n",
    "\n",
    "    V = V.values.tolist()\n",
    "    P1 = P1.values.tolist()\n",
    "    P2 = P2.values.tolist()\n",
    "\n",
    "    n = len(P1)\n",
    "    mean = 0.0\n",
    "    loss1 = 0.0\n",
    "    loss2 = 0.0\n",
    "    D: List[float] = []\n",
    "\n",
    "    '''\n",
    "    l1 += loss(v, p1)\n",
    "    l2 += loss(v, p2)\n",
    "    mean += l1 - l2\n",
    "    '''\n",
    "    for i in range(0,n):\n",
    "        l1 = loss(V[i][0], P1[i][0])\n",
    "        l2 = loss(V[i][0], P2[i][0])\n",
    "        D.append(l1 - l2)\n",
    "        mean += l1 - l2\n",
    "        loss1 += l1\n",
    "        loss2 += l2\n",
    "\n",
    "    mean /= n\n",
    "    \n",
    "    '''\n",
    "    for v, p1, p2 in zip(V, P1, P2):\n",
    "        l1 = loss(v, p1)\n",
    "        l2 = loss(v, p2)\n",
    "        D.append(l1 - l2)\n",
    "        mean += l1 - l2\n",
    "        loss1 += l1\n",
    "        loss2 += l2\n",
    "\n",
    "    mean /= n\n",
    "    '''\n",
    "    \n",
    "    V_d = 0.0\n",
    "    for i in range(h):\n",
    "        V_d += autocovariance(D, i, mean)\n",
    "        if i == 0:\n",
    "            V_d /= 2\n",
    "\n",
    "    V_d = 2 * V_d / n\n",
    "\n",
    "    if V_d == 0:\n",
    "        raise ZeroVarianceException(\n",
    "            \"Variance of the DM statistic is zero. Maybe the prediction series are identical?\"\n",
    "        )\n",
    "\n",
    "    if harvey_correction:\n",
    "        harvey_adj = sqrt((n + 1 - 2 * h + h * (h - 1) / n) / n)\n",
    "        dmstat = harvey_adj / sqrt(V_d) * mean\n",
    "    else:\n",
    "        dmstat = mean / sqrt(V_d)\n",
    "\n",
    "    pvalue = regularized_incomplete_beta(\n",
    "        (n - 1) / ((n - 1) + dmstat ** 2), 0.5 * (n - 1), 0.5\n",
    "    )\n",
    "\n",
    "    if one_sided:\n",
    "        pvalue = pvalue / 2 if dmstat < 0 else 1 - pvalue / 2\n",
    "\n",
    "    return dmstat, pvalue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0c357375-fab1-4e63-99b8-af422d5ac3d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_diebold_mariano(dataset, target_var, model_1, model_2):\n",
    "    pred = dataset.copy()\n",
    "    if len(pred[[model_1]].dropna()) < len(pred[[model_2]].dropna()):\n",
    "        model_1_val = pred[[model_1]].dropna()\n",
    "        window_start = model_1_val.index[0]\n",
    "        window_end = model_1_val.index[-1]\n",
    "        model_2_val = pred[[model_2]].loc[window_start:window_end].copy()\n",
    "        y_val = pred[[target_var]].loc[window_start:window_end].copy()\n",
    "\n",
    "\n",
    "        return model_1_val, model_2_val, y_val\n",
    "    else:\n",
    "        model_2_val = pred[[model_2]].dropna()\n",
    "        window_start = model_2_val.index[0]\n",
    "        window_end = model_2_val.index[-1]\n",
    "        model_1_val = pred[[model_1]].loc[window_start:window_end].copy()\n",
    "        y_val = pred[[target_var]].loc[window_start:window_end].copy()\n",
    "\n",
    "        return model_1_val, model_2_val, y_val\n",
    "\n",
    "def evaluate_pvalue(pvalue):\n",
    "    if pvalue < 0.05:\n",
    "    #non-equivalent, i.e. we reject the null hypothesis that both models have equal predictive capability\n",
    "    #non-equivalence in RED\n",
    "        pvalue = -1\n",
    "    else:\n",
    "    #pvalue > 0.05\n",
    "    #equivalent, i.e. we accept the null hypothesis that both models have equal predictive capability\n",
    "    #not enough evidence to show that one model predictive better than the other\n",
    "    #equivalence in BLACK\n",
    "        pvalue = 1\n",
    "    return pvalue\n",
    "\n",
    "def generate_diebold_mariano(dataset, target_var):\n",
    "    pred = dataset.copy()\n",
    "    model_list = list(pred.columns.values)\n",
    "    y = pred[[target_var]]\n",
    "    model_list.remove(target_var)\n",
    "\n",
    "    diebold_mariano_dmstat_df = pd.DataFrame(index=model_list, columns=model_list)\n",
    "    diebold_mariano_pvalue_df = pd.DataFrame(index=model_list, columns=model_list)\n",
    "    \n",
    "    for model_1 in model_list:\n",
    "        for model_2 in model_list:\n",
    "            if model_1 == model_2:\n",
    "                dm_stat, pvalue = 0, 0\n",
    "            else:\n",
    "                if pd.isna(diebold_mariano_pvalue_df.loc[model_2, model_1]):\n",
    "                    model_1_val, model_2_val, y_val = prepare_diebold_mariano(pred, target_var, model_1, model_2)\n",
    "                    dm_stat, pvalue = dm_test(y_val, model_1_val, model_2_val, one_sided=False)\n",
    "                    pvalue = evaluate_pvalue(pvalue)\n",
    "                else:\n",
    "                    dm_stat, pvalue = 0, 0\n",
    "            diebold_mariano_dmstat_df.at[model_1, model_2], diebold_mariano_pvalue_df.at[model_1, model_2] = dm_stat, pvalue\n",
    "    return diebold_mariano_dmstat_df, diebold_mariano_pvalue_df\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9d512ac0-8694-479e-b44d-37c18e404c3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def combined_error_metrics(target_var, pred_directory, pred_combi_directory, pred_2_directory):\n",
    "    pred_dir = os.path.join(target_var, pred_directory)\n",
    "    pred_combi_dir = os.path.join(target_var, pred_combi_directory)\n",
    "    pred_2_dir = os.path.join(target_var, pred_2_directory)\n",
    "    print(pred_dir)\n",
    "    for filename in os.listdir(pred_dir):\n",
    "        print(filename)\n",
    "        pred_file = os.path.join(pred_dir, filename)\n",
    "        pred_combi_file = os.path.join(pred_combi_dir, filename)\n",
    "        pred_2_file = os.path.join(pred_2_dir, filename)\n",
    "        # checking if it is a file\n",
    "        if os.path.isfile(pred_file):\n",
    "            #print(pred_file)\n",
    "            y_pred = pd.read_csv(pred_file, parse_dates = [0], dayfirst = True)\n",
    "            y_pred['epiweek'] = y_pred['epiweek'].apply(create_epiweek_fromstr)\n",
    "            y_pred = y_pred.set_index('epiweek')\n",
    "\n",
    "            y_pred_combi = pd.read_csv(pred_combi_file, parse_dates = [0], dayfirst = True)\n",
    "            y_pred_combi['epiweek'] = y_pred_combi['epiweek'].apply(create_epiweek_fromstr)\n",
    "            y_pred_combi = y_pred_combi.set_index('epiweek')\n",
    "            y_pred_combi = y_pred_combi.drop(target_var, axis=1)\n",
    "\n",
    "            y_all = pd.concat([y_pred, y_pred_combi], axis = 'columns')\n",
    "            \n",
    "            pred_all_path = os.path.join(target_var, 'pred_all')\n",
    "            if not os.path.exists(pred_all_path):\n",
    "                os.makedirs(pred_all_path)\n",
    "            y_all.to_csv(os.path.join(pred_all_path, filename))\n",
    "\n",
    "            error_df = generate_error_metrics(y_all, target_var)\n",
    "\n",
    "            error_metrics_path = os.path.join(target_var, 'error_metrics')\n",
    "            if not os.path.exists(error_metrics_path):\n",
    "                os.makedirs(error_metrics_path)        \n",
    "            error_df.to_csv(os.path.join(error_metrics_path, filename))\n",
    "\n",
    "            \n",
    "            diebold_mariano_dmstat_df, diebold_mariano_pvalue_df = generate_diebold_mariano(y_all, target_var)\n",
    "            \n",
    "            dmstat_path = os.path.join(target_var, 'dmstat')\n",
    "            if not os.path.exists(dmstat_path):\n",
    "                os.makedirs(dmstat_path)\n",
    "            diebold_mariano_dmstat_df.to_csv(os.path.join(dmstat_path, filename))\n",
    "\n",
    "            pvalue_path = os.path.join(target_var, 'pvalue')\n",
    "            if not os.path.exists(pvalue_path):\n",
    "                os.makedirs(pvalue_path)\n",
    "            diebold_mariano_pvalue_df.to_csv(os.path.join(pvalue_path, filename))\n",
    "\n",
    "            ## ADD y_full to include pred_2\n",
    "\n",
    "            y_pred_2 = pd.read_csv(pred_2_file, parse_dates = [0], dayfirst = True)\n",
    "            y_pred_2['epiweek'] = y_pred_2['epiweek'].apply(create_epiweek_fromstr)\n",
    "            y_pred_2 = y_pred_2.set_index('epiweek')\n",
    "            y_pred_2 = y_pred_2.drop(target_var, axis=1)\n",
    "\n",
    "            y_full = pd.concat([y_pred, y_pred_combi, y_pred_2], axis = 'columns')\n",
    "            y_full = y_full.dropna()\n",
    "\n",
    "            pred_full_path = os.path.join(target_var, 'pred_full')\n",
    "            if not os.path.exists(pred_full_path):\n",
    "                os.makedirs(pred_full_path)\n",
    "            y_full.to_csv(os.path.join(pred_full_path, filename))\n",
    "\n",
    "            error_df_full = generate_error_metrics(y_full, target_var)\n",
    "\n",
    "            error_metrics_full_path = os.path.join(target_var, 'error_metrics_full')\n",
    "            if not os.path.exists(error_metrics_full_path):\n",
    "                os.makedirs(error_metrics_full_path)        \n",
    "            error_df_full.to_csv(os.path.join(error_metrics_full_path, filename))\n",
    "\n",
    "            '''\n",
    "            \n",
    "            diebold_mariano_dmstat_full_df, diebold_mariano_pvalue_full_df = generate_diebold_mariano(y_full, target_var)\n",
    "            \n",
    "            dmstat_full_path = os.path.join(target_var, 'dmstat_full')\n",
    "            if not os.path.exists(dmstat_full_path):\n",
    "                os.makedirs(dmstat_full_path)\n",
    "            diebold_mariano_dmstat_full_df.to_csv(os.path.join(dmstat_full_path, filename))\n",
    "\n",
    "            pvalue_full_path = os.path.join(target_var, 'pvalue_full')\n",
    "            if not os.path.exists(pvalue_full_path):\n",
    "                os.makedirs(pvalue_full_path)\n",
    "            diebold_mariano_pvalue_full_df.to_csv(os.path.join(pvalue_full_path, filename))\n",
    "            '''\n",
    "\n",
    "            #print(error_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "dd2a0916-8c33-4078-9d6f-295ffa700aee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Cardiovascular disease', 'Chronic respiratory disease', 'Factors influencing health status and contact with health services', 'Digestive disease', 'Endocrine disorders', 'Malignant neoplasms', 'Diabetes mellitus', 'Genitourinary disorders', 'Musculoskeletal disease', 'Infectious and Parasitic Diseases', 'Ill-defined diseases', 'Neurological and sense disorders', 'Oral Diseases', 'Other neoplasms', 'Respiratory Infection', 'Skin diseases']\n",
      "[Parallel(n_jobs=-2)]: Using backend LokyBackend with 11 concurrent workers.\n",
      "[Parallel(n_jobs=-2)]: Done   1 tasks      | elapsed:    3.6s\n",
      "[Parallel(n_jobs=-2)]: Done   2 out of  16 | elapsed:    3.6s remaining:   25.0s\n",
      "[Parallel(n_jobs=-2)]: Done   3 out of  16 | elapsed:    3.6s remaining:   15.8s\n",
      "[Parallel(n_jobs=-2)]: Done   4 out of  16 | elapsed:    3.7s remaining:   11.1s\n",
      "[Parallel(n_jobs=-2)]: Done   5 out of  16 | elapsed:    3.7s remaining:    8.1s\n",
      "[Parallel(n_jobs=-2)]: Done   6 out of  16 | elapsed:    4.1s remaining:    6.8s\n",
      "[Parallel(n_jobs=-2)]: Done   7 out of  16 | elapsed:    4.2s remaining:    5.4s\n",
      "[Parallel(n_jobs=-2)]: Done   8 out of  16 | elapsed:    4.2s remaining:    4.2s\n",
      "[Parallel(n_jobs=-2)]: Done   9 out of  16 | elapsed:    4.2s remaining:    3.3s\n",
      "[Parallel(n_jobs=-2)]: Done  10 out of  16 | elapsed:    4.2s remaining:    2.5s\n",
      "[Parallel(n_jobs=-2)]: Done  11 out of  16 | elapsed:    4.2s remaining:    1.9s\n",
      "[Parallel(n_jobs=-2)]: Done  12 out of  16 | elapsed:    5.8s remaining:    1.9s\n",
      "[Parallel(n_jobs=-2)]: Done  13 out of  16 | elapsed:    5.9s remaining:    1.4s\n",
      "[Parallel(n_jobs=-2)]: Done  14 out of  16 | elapsed:    5.9s remaining:    0.8s\n",
      "[Parallel(n_jobs=-2)]: Done  16 out of  16 | elapsed:    6.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=-2)]: Done  16 out of  16 | elapsed:    6.0s finished\n"
     ]
    }
   ],
   "source": [
    "def full_combined_error_metrics(target_variables_file, pred_directory, pred_combi_directory, pred_2_directory):\n",
    "    target_variables = []\n",
    "    with open(target_variables_file, 'r') as file:\n",
    "        for line in file:\n",
    "            # Remove linebreak which is the last character of the string\n",
    "            target_variable = line[:-1]\n",
    "            # Add item to the list\n",
    "            target_variables.append(target_variable)\n",
    "    print(target_variables)\n",
    "\n",
    "    Parallel(n_jobs=-2, verbose=51)(delayed(combined_error_metrics)(target_var, \n",
    "                                                                    pred_directory, \n",
    "                                                                    pred_combi_directory,\n",
    "                                                                    pred_2_directory) for target_var in target_variables)\n",
    "    \n",
    "full_combined_error_metrics('target_variables.txt', 'pred','pred_combi','pred_2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64a51a91-1017-4550-bd1e-aee71501166d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be6901d1-39ea-4dca-b480-e7a87f73385c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
